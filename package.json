{
  "name": "@elizaos/plugin-livekit",
  "version": "1.0.2",
  "type": "module",
  "main": "dist/index.js",
  "module": "dist/index.js",
  "types": "dist/index.d.ts",
  "exports": {
    "./package.json": "./package.json",
    ".": {
      "import": {
        "@elizaos/source": "./src/index.ts",
        "types": "./dist/index.d.ts",
        "default": "./dist/index.js"
      }
    }
  },
  "files": [
    "dist"
  ],
  "dependencies": {
    "@elizaos/core": "^1.0.0",
    "@livekit/components-react": "^2.9.4",
    "@livekit/rtc-node": "^0.13.13",
    "livekit-client": "^2.11.4",
    "livekit-server-sdk": "^2.12.0",
    "eventemitter3": "^5.0.1"
  },
  "devDependencies": {
    "tsup": "8.3.5",
    "vitest": "^3.0.0"
  },
  "scripts": {
    "build": "cd src/frontend && bun run build && cd ../.. && tsup src/index.ts --format esm --dts --tsconfig ./tsconfig.json",
    "build:frontend": "cd src/frontend && bun run build",
    "dev": "tsup src/index.ts --format esm --dts --watch --tsconfig ./tsconfig.json",
    "test": "npx elizaos test"
  },
  "agentConfig": {
    "pluginType": "elizaos:client:1.0.0",
    "pluginParameters": {
      "LIVEKIT_URL": {
        "type": "string",
        "description": "WebSocket URL of the LiveKit server to connect to when joining a voice room; used if not provided in the handler options.",
        "required": false,
        "default": "ws://localhost:7880",
        "sensitive": false
      },
      "VITE_SERVER_PORT": {
        "type": "string",
        "description": "The server port used to build the API base URL for fetch requests during runtime.",
        "required": false,
        "default": "3000",
        "sensitive": false
      },
      "VITE_LIVEKIT_URL": {
        "type": "string",
        "description": "The LiveKit WebSocket server URL used by the client to establish voice chat connections.",
        "required": false,
        "default": "wss://lvie-fd0we5n9.livekit.cloud",
        "sensitive": false
      },
      "VITE_API_BASE_URL": {
        "type": "string",
        "description": "Base URL for API requests used by the Vite front-end.",
        "required": true,
        "sensitive": false
      },
      "SERVER_PORT": {
        "type": "string",
        "description": "Port number where the backend server is expected to run; its value is injected into the client build as import.meta.env.VITE_SERVER_PORT.",
        "required": false,
        "default": "3000",
        "sensitive": false
      },
      "LIVEKIT_API_KEY": {
        "type": "string",
        "description": "API key used to authenticate with the LiveKit server.",
        "required": false,
        "sensitive": true
      },
      "LIVEKIT_API_SECRET": {
        "type": "string",
        "description": "API secret used to authenticate with the LiveKit server.",
        "required": false,
        "sensitive": true
      },
      "LIVEKIT_ENABLE_TURN_DETECTION": {
        "type": "boolean",
        "description": "Flag that enables or disables voice turn detection logic in the LiveKitService.",
        "required": false,
        "default": true,
        "sensitive": false
      },
      "LIVEKIT_SILENCE_THRESHOLD": {
        "type": "number",
        "description": "Audio energy threshold below which audio is treated as silence during voice activity detection.",
        "required": false,
        "default": 0.01,
        "sensitive": false
      },
      "LIVEKIT_SPEECH_THRESHOLD": {
        "type": "number",
        "description": "Audio energy threshold above which audio is treated as speech during voice activity detection.",
        "required": false,
        "default": 0.1,
        "sensitive": false
      },
      "LIVEKIT_MIN_SPEECH_DURATION": {
        "type": "number",
        "description": "Minimum duration in milliseconds that speech must last to be considered a valid speech segment.",
        "required": false,
        "default": 500,
        "sensitive": false
      },
      "LIVEKIT_MAX_SPEECH_DURATION": {
        "type": "number",
        "description": "Maximum duration in milliseconds allowed for a single speech segment before it is automatically cut off.",
        "required": false,
        "default": 30000,
        "sensitive": false
      },
      "LIVEKIT_DEBOUNCE_THRESHOLD": {
        "type": "number",
        "description": "Time in milliseconds used to debounce between speech segments to avoid rapid toggling.",
        "required": false,
        "default": 1500,
        "sensitive": false
      },
      "LIVEKIT_SILENCE_FRAMES_REQUIRED": {
        "type": "number",
        "description": "Number of consecutive silence frames required to classify the end of speech.",
        "required": false,
        "default": 150,
        "sensitive": false
      },
      "LIVEKIT_SPEECH_FRAMES_REQUIRED": {
        "type": "number",
        "description": "Number of consecutive speech frames required to classify the start of speech.",
        "required": false,
        "default": 3,
        "sensitive": false
      },
      "LIVEKIT_SAMPLE_RATE": {
        "type": "number",
        "description": "Sample rate in hertz used for audio processing and resampling operations.",
        "required": false,
        "default": 48000,
        "sensitive": false
      },
      "LIVEKIT_CHANNELS": {
        "type": "number",
        "description": "Number of audio channels (1 for mono, 2 for stereo) used in audio processing.",
        "required": false,
        "default": 1,
        "sensitive": false
      },
      "LIVEKIT_FRAME_SIZE": {
        "type": "number",
        "description": "Number of samples per audio frame used during audio capture and processing.",
        "required": false,
        "default": 480,
        "sensitive": false
      }
    }
  }
}
